---
title: "Market Model"
format: html
---

```{r}
#| warning: false
#| echo: false
source('functions.R')
target_label = credit_card.target_label()
ubpr_labels =  credit_card.udpr()

```
## Specification {#sec-model-market}

To determine the normal return we can adopt the market model [@MacKinlay1997]
$$
D_{it} = \alpha_i + \beta_i D_{gt} + \epsilon_{it}
$$

And the AR is 
$$
AR_{it} = D_{it} – (\alpha_i + \beta_i D_{gt})
$$

Where:

$D_{it}$ is *`r target_label`* (differenced) $i$ at time $t$, \
$\alpha_i$ is the firm-specific intercept, \
$\beta_i$ is the sensitivity of firm value $i$ to the group $g$,\
$D_{gt}$ is the group *`r target_label`* (differenced) at time $t$, and \
$\varepsilon_{it}$ is the error term for $i$ at time $t$.

## Model Results

```{r}
#| warning: false
data <- get_model_data() |> drop_na(UBPRE524.diff)

estimation_data <- data |> filter(is.na(Partnership)) |> fill_gaps()
observation_data <- data |> filter(!is.na(Partnership))

market_formula <- "UBPRE524.diff ~ UBPRE524.group.diff"
m_table <- estimation_data |> fabletools::model(tslm = TSLM(as.formula(market_formula)))
augmented_data <- m_table |> augment()
```

### Estimated Fit

As outlined in @sec-data-split, we have split our data into estimation and observation periods. For firms that do not have partnership events, the full data series is used in the estimation period. For firms with partnership events the estimation period is up to the quarter before each event. 

If the market model demonstrates a robust fit with the estimation data, this instills confidence in our ability to forecast the "normal" return using the unseen data from the observation period.

@fig-plot-fit displays fitted vs actual results for a sub-set of firms. The Intercept and Coefficient is displayed in @tbl-coef-market. The model is   

```{r}
#| warning: false
#| label: fig-plot-fit
#| fig-cap: "Fitted vs. Observed for estimation data on sub-set of firms"
#| fig-height: 10
augmented_data |> filter(BankName %in% unique(observation_data$BankName)) |>
        plot_model_fit("UBPRE524.diff")
```

```{r}
#| warning: false
#| label: tbl-market-aicc
#| tbl-cap: AICc Summary for sub-set of banks
m_table |> filter(BankName %in% observation_data$BankName) |> glance() |> relocate(BankName, AICc, AIC) |> select(-IDRSSD)|>
    mutate(across(where(is.numeric), \(x) round(x,4))) |>  
    rmarkdown::paged_table()  
```
```{r}
#| warning: false
#| label: tbl-coef-market
#| tbl-cap: "Intercept and coefficients"
m_table |> filter(BankName %in% unique(observation_data$BankName)) |> 
  tidy() |> select(BankName, term:last_col())|>
    mutate(across(where(is.numeric), \(x) round(x,4))) |>  
    rmarkdown::paged_table()
```
### Residual diagnostics {#sec-residual-check}

Residuals should have the following properties [@Hyndman2021, ch. 5.4]. Residuals:

* Are uncorrelated. Correlations indicate that the model is missing information left in the residuals.
* Have zero mean. If they have a mean other than zero, then the forecasts are biased.
* Have constant variance i.e. does not violate "homoscedasticity" assumption.
* Are normally distributed. 

::: {#fig-market-checks .panel-tabset}

### CITIBANK
```{r}
#| warning: false
#| label: fig-fit-citi
#| fig-subcap: 
#|   - "The time plot of the residuals shows that the variation of the residuals is relatively constant but with one significant outlier. The acf shows residuals are uncorrelated, and the residuals look normal with the exception of the outlier." 
#|   - "Explaining the outlier: Deliquency dropped at a time when CITIBANK's credit card portfolio became a larger business concern (c). The borrowers added appear to be less risky as we see the unused proportion go from below 10% to over 40% in (b)"

bank <- "CITIBANK"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data,ubpr_labels)
```

### SYNCHRONY
```{r}
#| warning: false
#| label: fig-fit-sync
#| fig-subcap: 
#|   - "The time plot of the residuals shows a couple of outliers at the start of the time period and in 2018 Q1. The acf shows residuals are uncorrelated, and the residuals look normal with the exception of the outliers." 
#|   - "Comparative credit card portfolio variables"

bank <- "SYNCHRONY"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data,ubpr_labels)
```
### BARCLAYS

```{r}
#| warning: false
#| label: fig-fit-bar
#| fig-subcap: 
#| - "The time plot of the residuals shows that the variation of the residuals is relatively constant up until the onset of the COVID-19 pandemic in 2020; the model needs more information to account for this period. The acf shows residuals are uncorrelated"
#| - "Comparative credit card portfolio variables"
bank <- "BARCLAYS"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data,ubpr_labels)
```

### AMERICAN EXPRESS
```{r}
#| warning: false
#| label: fig-fit-ae
#| fig-subcap: 
#| - "The time plot of the residuals shows a couple of outliers at the start of the time period causing a left skew. The acf shows residuals are uncorrelated."
#| - "Comparative credit card portfolio variables"

bank <- "AMERICAN EXPRESS NATIONAL BANK"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data,ubpr_labels)

```
### CAPITAL ONE
```{r}
#| warning: false
#| label: fig-fit-cap
#| fig-subcap: 
#|   - "The time plot of the residuals shows that the variation of the residuals is relatively constant but with two significant outliers at the start of the series. The acf shows residuals are uncorrelated, and the residuals look normal with the exception of the outliers." 
#|   - "Explaining the outlier: Deliquency dropped at a time when CAPITAL ONE's credit card portfolio became a larger business concern. The U shape for deliquency % indicates initial improvement in the portfolio's quality, however, by the end of the estimation period, the % is back up. This increase coincides with a decrease in unused commitments i.e. borrowers are putting more expenditures on their credit cards."

bank <- "CAPITAL ONE"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data, ubpr_labels)
```
:::

### Residuals White Noise

The sub-set of banks analysed in @sec-residual-check did not exhibit significant autocorrelation.

@tbl-lb-market lists banks where we reject the null hypothesis of the Ljung–Box test, indicating the presence of significant autocorrelation in the residuals. 

Banks not listed have residuals that are indistinguishable from a white noise series i.e. have uncorrelated observations and with constant variance.

```{r}
#| warning: false
#| label: tbl-lb-market
#| tbl-cap: Ljung–Box results where P-value < Significance Level of 0.05
augmented_data  |>
  features(.innov, ljung_box) |> mutate(across(where(is.numeric), \(x) round(x,4))) |> 
    filter(lb_pvalue <= 0.05)|> select(BankName,lb_stat,lb_pvalue) |>
      rmarkdown::paged_table()
```

## Time Series Cross-Validation

One approach to evaluate the predictive performance of our model is to use One-step ahead cross-validation, also known as walk-forward validation, which is specifically designed for time series.

```{r}
#| warning: false
#| output: false
#| eval: false

m_table |> fabletools::accuracy()|> readr::write_csv("data/results/estimate_market_metrics.csv")

# Timeseries CV 
est_data_tr <- estimation_data |>
                    stretch_tsibble(.init = 3, .step = 1) |>
                    relocate( .id)

# TSCV accuracy
est_data_tr |>
  model(tslm = TSLM(as.formula(market_formula))) |>
  forecast(new_data = est_data_tr) |>
  fabletools::accuracy(estimation_data)|> 
  readr::write_csv("data/results/estimate_tscv_market_metrics.csv")

```


```{r}
#| warning: false
#| label: tbl-market-cv
#| tbl-cap: Comparing Accuracy Metrics for Training and Cross-Validation data
#| tbl-subcap: 
#| - Accuracy Metrics on Training and Cross Validation data for sub-set of banks
#| - Mean Accuracy Metrics for our sub-set of banks
#| - Mean Accuracy Metrics across all banks
cv_results_est <- readr::read_csv("data/results/estimate_market_metrics.csv",show_col_types = FALSE) |> select(-.model) |>
  mutate(across(where(is.numeric), \(x) round(x,4))) |> 
  select(BankName, .type, RMSE, MAE)

cv_results_test <-readr::read_csv("data/results/estimate_tscv_market_metrics.csv",show_col_types = FALSE) |> select(-.model) |>
  mutate(across(where(is.numeric), \(x) round(x,4))) |> 
    select(BankName, .type, RMSE, MAE) |> mutate(.type = "CV")
      
comb <- bind_rows(cv_results_est, cv_results_test) 
comb |> filter(BankName %in% observation_data$BankName) |> arrange(BankName,.type) |> rmarkdown::paged_table()     

comb |> filter(BankName %in% observation_data$BankName) |> 
  group_by(.type) |> summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) |>
    rmarkdown::paged_table()  

comb |> group_by(.type) |> 
  summarise(across(where(is.numeric), \(x) mean(x, na.rm = TRUE))) |> 
    rmarkdown::paged_table()     

```

## Prediction 

```{r}
#| warning: false
#| echo: false
#| results: hide
#| fig-keep: all
#| label: fig-pred-observed
#| fig-cap: "Prediction vs. Observed Event"

plot_prediction <- function(Bank, Partner, all_data, models) {
  est_data <- all_data |> filter(BankName == Bank, is.na(!!as.name(Partner)))
  est_data_trunc <- est_data |> tail(ifelse(nrow(est_data)<11,nrow(est_data),11))
  event_data <- all_data |> filter(BankName == Bank, 
                                          !!as.name(Partner) >=0) |> head(8) 
  comb_data <- bind_rows(est_data_trunc, event_data)

  models |>
    filter(BankName == Bank)  |>
    forecast(new_data= event_data) |>
    filter(.model=='tslm') |> 
    autoplot()  + 
    geom_line(aes(x = Quarter, y=UBPRE524.diff), data = comb_data, colour='darkslategrey',linetype = "longdash") +
    labs(title = Bank, subtitle = glue("{Partner}"), y = glue("{target_label} (differenced)"))
}


get_prediction <- function(Bank, Partner, all_data, models) {
  est_data <- all_data |> filter(BankName == Bank, is.na(!!as.name(Partner)))
  est_data_trunc <- est_data |> tail(ifelse(nrow(est_data)<11,nrow(est_data),11))
  event_data <- all_data |> filter(BankName == Bank, 
                                          !!as.name(Partner) >=0) |> head(8) 
  models |>
    filter(BankName == Bank)  |>
    forecast(new_data= event_data) |> add_column(Partner = Partner)    
}


partner_banks <- credit_card.partnerships() |> 
                  pivot_longer(cols = c("Old","New")) |> 
                      distinct(Bank = value, Partner)

map2(partner_banks$Bank, partner_banks$Partner, plot_prediction, data, m_table) 


result <- map2(partner_banks$Bank, partner_banks$Partner, get_prediction, data, m_table)  |> 
  list_rbind() |> left_join(data |> select(Observed = UBPRE524.diff),by = join_by(IDRSSD, BankName, BankType, Quarter) ) |> as_tibble() |> select(Partner,BankName, Quarter, Observed, Predicted = .mean) |> mutate(AR = Observed - Predicted)

# result |> group_by(Partner,BankName) |> mutate(Period = row_number()) |> ggplot(aes(x=Period, y=AR, color=BankName))  + geom_line() + facet_wrap(~Partner, ncol=1)

# result |> group_by(Partner,BankName) |> summarise(mean_ar = mean(AR, na.rm=TRUE))

result |> group_by(Partner,BankName) |> summarise(median_ar = median(AR, na.rm=TRUE))



```

## References