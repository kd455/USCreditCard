---
title: "Market Model"
format: html
---

```{r}
#| warning: false
#| echo: false
source('functions.R')
target_label = credit_card.target_label()
ubpr_labels =  credit_card.udpr()

ubpr_labels |> filter(UBPR_Code == "UBPRB538")

plot_cc_measures <- function(bank_fuzzy, data, ubpr_labels) {
  data |> filter(grepl(bank_fuzzy,BankName)) |> 
  select(UBPRE524 = UBPRE524.Value, UBPRE263 = UBPRE263.Value, UBPRE425 = UBPRE425.Value, UBPRB538 = UBPRB538.Value) |> 
   pivot_longer(cols= -Quarter, names_to = "UBPR_Code") |> 
   mutate(display_order = case_when(
                          UBPR_Code == "UBPRE524" ~ "(a)",
                          UBPR_Code == "UBPRE263" ~ "(b)",
                          UBPR_Code == "UBPRE425" ~ "(c)",
                          UBPR_Code == "UBPRB538" ~ "(d)"),
                          .default = "" ) |>
   left_join(ubpr_labels,by = join_by(UBPR_Code)) |> 
   mutate(Description = paste(display_order, Description)) |>
   ggplot(aes(x = Quarter, y =value, colour = UBPR_Code)) + 
   geom_line() + 
   labs(y='') +
   theme(legend.position = "none") +
   facet_wrap(~Description, scales = "free_y", ncol=1)
}

```
## Specification {#sec-model-market}

To determine the normal return we can adopt the market model [@MacKinlay1997]
$$
D_{it} = \alpha_i + \beta_i D_{gt} + \epsilon_{it}
$$

And the AR is 
$$
AR_{it} = D_{it} – (\alpha_i + \beta_i D_{gt})
$$

Where:

$D_{it}$ is *`r target_label`* (differenced) $i$ at time $t$, \
$\alpha_i$ is the firm-specific intercept, \
$\beta_i$ is the sensitivity of firm value $i$ to the group $g$,\
$D_{gt}$ is the group *`r target_label`* (differenced) at time $t$, and
$\varepsilon_{it}$ is the error term for $i$ at time $t$.

## Model Results

```{r}
#| warning: false
data <- get_model_data() |> drop_na(UBPRE524.diff)

estimation_data <- data |> filter(is.na(Partnership)) |> fill_gaps()
observation_data <- data |> filter(!is.na(Partnership))

results <- tibble(model = character(),
                    rsme = numeric())

market_formula <- "UBPRE524.diff ~ UBPRE524.group.diff"
m_table <- estimation_data |> fabletools::model(tslm = TSLM(as.formula(market_formula)))
augmented_data <- m_table |> augment()

# m_table |> 
#   tidy() |> 
#     mutate(across(where(is.numeric), \(x) round(x,2))) |> 
#       rmarkdown::paged_table()
```

### Estimated Fit

As outlined in @sec-data-split, we have split our data into estimation and observation periods. For firms that do not have partnership events, the full data series is used in the estimation period. For firms with partnership events the estimation period is until the quarter before each event. 

If the market model demonstrates a robust fit with the estimation data, this instills confidence in our ability to forecast the "normal" return using the fresh, unseen data from the observation period.

@fig-plot-fit displays some of the fitted vs actual results. 

```{r}
#| warning: false
#| label: fig-plot-fit
#| fig-cap: "Fitted vs. Observed for estimation data on sub-set of firms"
augmented_data |> filter(BankName %in% unique(observation_data$BankName)) |>
        autoplot(UBPRE524.diff, colour = "darkgrey") + 
        geom_line(aes(y = .fitted, colour = "#D55E00")) + facet_wrap(~BankName+BankType, ncol = 2) +
        labs(title = "<span style='color:#D55E00'>Fitted</span> vs. <span style='color:darkgrey'>Observed</span>",
        y = glue("{target_label} (differenced)")) +
        theme(legend.position = "none", plot.title = element_markdown(),plot.subtitle = element_markdown()) 
```
### Residual diagnostics {#sec-residual-check}

Residuals should have the following properties [@Hyndman2021, ch. 5.4]. Residuals:

* Are uncorrelated. Correlations indicate that the model is missing information left in the residuals.
* Have zero mean. If they have a mean other than zero, then the forecasts are biased.
* Have constant variance i.e. does not violate "homoscedasticity" assumption.
* Are normally distributed. 

::: {#fig-market-checks .panel-tabset}

### CITIBANK
```{r}
#| warning: false
#| label: fig-fit-citi
#| fig-subcap: 
#|   - "The time plot of the residuals shows that the variation of the residuals is relatively constant but with one significant outlier. The acf shows residuals are uncorrelated, and the residuals look normal with the exception of the outlier." 
#|   - "Explaining the outlier: Deliquency dropped at a time when CITIBANK's credit card portfolio became a larger business concern (c). The borrowers added appear to be less risky as we see the unused proportion go from below 10% to over 40% in (b)"

bank <- "CITIBANK"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  

plot_cc_measures(bank, estimation_data,ubpr_labels)

```

### BARCLAYS

```{r}
#| warning: false
#| label: fig-fit-bar
#| fig-subcap: 
#| - "The time plot of the residuals shows that the variation of the residuals is relatively constant up until the onset of the COVID-19 pandemic in 2020; the model needs more information to account for this period. The acf shows residuals are uncorrelated"
#| - ""
bank <- "BARCLAYS"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  

plot_cc_measures(bank, estimation_data,ubpr_labels)
```


### AMERICAN EXPRESS
```{r}
#| warning: false
#| label: fig-fit-ae
#| fig-subcap: 
#| - "The time plot of the residuals shows that the variation of the residuals is relatively constant. The acf shows residuals are uncorrelated. and  normally distributed."
#| - "Explaining the outlier: Deliquency dropped at a time when CITIBANK's credit card portfolio became a larger business concern. The borrowers added appear to be less risky as we see the unused proportion go from below 10% to over 40%"

bank <- "AMERICAN EXPRESS NATIONAL BANK"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  

plot_cc_measures(bank, estimation_data,ubpr_labels)

```

### CAPITAL ONE
```{r}
#| warning: false
#| label: fig-fit-cap
#| fig-subcap: 
#|   - "The time plot of the residuals shows that the variation of the residuals is relatively constant but with two significant outliers at the start of the series. The acf shows residuals are uncorrelated, and the residuals look normal with the exception of the outliers." 
#|   - "Explaining the outlier: Deliquency dropped at a time when CAPITAL ONE's credit card portfolio became a larger business concern. The U shape for deliquency % indicates initial improvement in the portfolio's quality, however, by the end of the estimation period, the % is back up. This increase coincides with a decrease in unused commitments i.e. borrowers are putting more expenditures on their credit cards."

bank <- "CAPITAL ONE"
m_table |> filter(grepl(bank,BankName)) |> select(tslm) |> gg_tsresiduals()  
plot_cc_measures(bank, estimation_data, ubpr_labels)

```

:::

### Residuals White Noise

The sub-set of banks analysed in @sec-residual-check did not exhibit significant autocorrelation.

@tbl-lb-test lists the results of Ljung–Box test for all banks filtered to those where we reject the null hypothesis, indicating the presence of significant autocorrelation in the residuals.  

The residuals for banks not listed are indistinguishable from a white noise series.

```{r}
#| warning: false
#| label: tbl-lb-test
#| tbl-cap: Ljung–Box results where P-value < Significance Level of 0.05
augmented_data  |>
  features(.innov, ljung_box) |> mutate(across(where(is.numeric), \(x) round(x,4))) |> 
    filter(lb_pvalue <= 0.05)|> select(BankName,lb_stat,lb_pvalue) |>
      rmarkdown::paged_table()
```

## Time Series Cross-Validation

Look-Ahead Bias: If data from after the test period is included in the training set, the model may inadvertently learn information from the future (known as "look-ahead bias"). This makes the model unrealistic and potentially over-optimistic in its predictive performance

To evaluating the predictive performance we use cross validation that are specifically for timeseries.One-step ahead cross-validation, also known as walk-forward validation, is a method specifically designed for evaluating the predictive performance of time series.

R package

```{r}
#| warning: false
#| output: false
#| eval: false

# Estimation Data 
m_table |> fabletools::accuracy()|> readr::write_csv("data/results/estimate_market_metrics.csv")

# Timeseries CV 

est_data_tr <- estimation_data |>
                    stretch_tsibble(.init = 3, .step = 1) |>
                    relocate( .id)

# TSCV accuracy
est_data_tr |>
  model(tslm = TSLM(as.formula(market_formula))) |>
  forecast(new_data = est_data_tr) |>
  fabletools::accuracy(estimation_data)|> 
  readr::write_csv("data/results/estimate_tscv_market_metrics.csv")

```


```{r}
#| warning: false
#| label: tbl-lb-cv
#| tbl-cap: Cross-Validation. Fit on Training and validation (Test)
cv_results_est <- readr::read_csv("data/results/estimate_market_metrics.csv",show_col_types = FALSE) |> select(-.model) |>
  mutate(across(where(is.numeric), \(x) round(x,4))) |> 
  relocate(.type, BankName, RMSE, MAE) |>
  rmarkdown::paged_table() 

cv_results_test <-readr::read_csv("data/results/estimate_tscv_market_metrics.csv",show_col_types = FALSE) |> select(-.model) |>
  mutate(across(where(is.numeric), \(x) round(x,4))) |> 
    relocate(.type, BankName, RMSE, MAE) |> mutate(.type = "CV")|> 
      rmarkdown::paged_table()

bind_rows(cv_results_est, cv_results_test) |> arrange(BankName,.type)      

```

## Prediction 

Observation Period...TO WRITE

```{r}
#| warning: false
#| echo: false
#| results: hide
#| fig-keep: all
#| label: fig-pred-bar
#| fig-cap: "Prediction vs. Observed Event"

plot_prediction <- function(bank_name, partner_name, estimation_data, observation_data, models) {
  est_data <- estimation_data |> filter(BankName == bank_name)
  est_data_trunc <- est_data |> tail(ifelse(nrow(est_data)<11,nrow(est_data),11))
  event_data <- observation_data |> filter(BankName == bank_name) |> head(5)
  comb_data <- bind_rows(est_data_trunc, event_data)

  models |>
    filter(BankName == bank_name)  |>
    forecast(new_data= event_data) |>
    filter(.model=='tslm') |> 
    autoplot()  + 
    geom_line(aes(x = Quarter, y=UBPRE524.diff), data = comb_data, colour='darkslategrey',linetype = "longdash") +
    labs(title = bank_name, subtitle = partner_name, y = glue("{target_label} (differenced)"))
}

partner_banks <- credit_card.partnerships() |> 
                  pivot_longer(cols = c("Old","New")) |> 
                      distinct(value,Partner = paste(Partner, "-", name))

map2(partner_banks$value, partner_banks$Partner, plot_prediction,estimation_data, observation_data, m_table)

#plot_prediction(bank_name, partner_name,estimation_data, observation_data, m_table )
```
### Abnormal Return


## References