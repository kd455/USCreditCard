---
title: "Event study"
format: html
---

```{r}
#| warning: false
#| echo: false
source('functions.R')
```

Event studies are a common approach in econometrics to assess the impact of an event such as earnings announcements, mergers and acquisitions, regulatory changes, or macroeconomic news.

The goal is to estimate the portion of post-event change that can be attributed to the event itself, isolating it from other market and firm-specific effects. We do this by predicting what would have happened if the event had not occurred (the counterfactual) and comparing it to the actual observed data to estimate the resulting *abnormal returns* (AR).

## Market Model

To determine the normal return we can adopt the market model [@MacKinlay1997]
$$
D_{it} = \alpha_i + \beta_i D_{gt} + \epsilon_{it}
$$

And the AR is 
$$
AR_{it} = D_{it} – (\alpha_i + \beta_i D_{gt})
$$

Where:

$D_{it}$ is *`r credit_card.target_label()`* (differenced) $i$ at time $t$,
$\alpha_i$ is the firm-specific *`r credit_card.target_label()`* (differenced),
$\beta_i$ is the sensitivity of firm value $i$ to the group $g$,
$D_{gt}$ is the group *`r credit_card.target_label()`* (differenced) at time $t$, and
$\varepsilon_{it}$ is the error term for $i$ at time $t$.

### Estimation and Observation Data

Following the process described by @HuntingtonKlein [chap 17.2.1], we pick an "estimation period" and an "observation period" from just before the event to the period of interest after the event.

The observation period includes 1 quarter before so we can determine if borrowers anticipate the event. This possibility was speculated in @sec-partners as we saw some fluctuation in credit card measures before the acquisition. 

### Sense check

The joint test problem arises because we are effectively testing two things: the counterfactual model and the event impact. Consequently, we need an approach to accurately evaluate if our counterfactual model results are credible. One approach suggested by @HuntingtonKlein is to test using observations where we expect no effect; if there were resulting "abnormal returns" this would point to an issue with the model.

This is in addition to visual, cross-validation and statistical checks on model fit.

```{r}
#| warning: false

data <- get_model_data() |> drop_na(UBPRE524.diff)

estimation_data <- data |> filter(is.na(Partnership))
observation_data <- data |> filter(!is.na(Partnership))

results <- tibble(model = character(),
                    rsme = numeric())

market_formula <- "UBPRE524.diff ~ UBPRE524.group.diff"
m <- lm(as.formula(market_formula), data = estimation_data)    
plot_fit(m, estimation_data, observation_data$BankName)

```
### Visual Checks

```{r}
#| warning: false
#| label: fig-fit
#| fig-cap: "Linear regression model diagnostics"
#| layout-ncol: 4
#| fig-subcap:
#|   - "Residuals vs Fitted - The red line is not perfectly flat suggesting we need to add additional interaction terms to better capture the relationship between the predictors and the response variable"
#|   - "Q-Q Residuals - the S shape indicates residuals have heavier tails"
#|   - "Scale-Location - the funnel shape indicates heteroscedasticity i.e. violates linear assumption of equal variance"
#|   - "Residuals vs Leverage - There are no points above Cook's distance threshold where removal of observation would change the regression coefficients"
#| 
plot(m,which = 1)
plot(m,which = 2)
plot(m,which = 3)
plot(m,which = 5)
```

### Cross-Validation

```{r}
#| warning: false
```


<!-- library(lme4)
library(Metrics)

source('functions.R')


data <- get_model_data() |> drop_na(UBPRE524.diff)

estimation_data <- data |> filter(is.na(Partnership))
event_data <- data |> filter(!is.na(Partnership))

results <- tibble(model = character(),
                    rsme = numeric())

#estimation_data |> select(starts_with("UBPRE524")) |>View()

market_formula <- "UBPRE524.diff ~ UBPRE524.group.diff"
trend_formula <- "UBPRE524.diff ~ UBPRE524.group.diff + trend() + season()"

fixed_formula <- "UBPRE524.diff ~ BankType*factor(Quarter) + (1|BankName)"

fixed_2way_formula <- "UBPRE524.diff ~  UBPRE524.group.diff | BankName + Quarter"
mixed_formula <- "UBPRE524.diff ~ BankType + (1 | BankName)"
hier_formula <- "UBPRE524.diff ~ BankType + (1 | BankType/IDRSSD) + UBPRE425.diff "



# Fit the models
fit <- estimation_data |> 
                model( lm = TSLM(as.formula(market_formula)) )

augmented_data <- fit |>
                    augment()

augmented_data |>  filter(BankName %in% event_data$BankName) |>
    autoplot(UBPRE524.diff, colour = "darkgrey") + 
    geom_line(aes(y = .fitted)) + facet_wrap(~BankName, ncol = 2) +
    theme(legend.position = "top") 

###########



AIC(m_market) #944.1663
fitted.values(m_market)
anova(m_market)
summary(m_market)
plot(m_market,which = 1)
plot(m_market,which = 2)
plot(m_market,which = 3)
plot(m_market,which = 4)
plot(m_market,which = 5)

augmented_data |>  filter(BankName %in% event_data$BankName) |>
    autoplot(UBPRE524.diff, colour = "darkgrey") + 
    geom_line(aes(y = .fitted)) + facet_wrap(~BankName, ncol = 2) +
    theme(legend.position = "top")

m_fixed <- lmer(as.formula(fixed_formula), data = estimation_data)
m_fixed2 <- feols(as.formula(fixed_2way_formula), data = estimation_data)
m_mixed <- lm(as.formula(mixed_formula), data = estimation_data)
m_hier <- lmer(as.formula(hier_formula), data = estimation_data)
summary(m_fixed2)
coef(m_fixed2)

feols(lifeExp ~ log(gdpPercap) | country + year,
             data = gm)

AIC(logLik(m_fixed))
AIC(m_fixed2)
BIC(m_fixed2)


install.packages("fixest")
library(fixest)
# Predict normal returns for the event window
event_data <- partner_data |> filter(EventPeriod == TRUE)

augmented_data <- event_data |>
                left_join(bank_mean) |>
                mutate(AR_mean = value_diff - value_diff.est.mean,
                AR_group = value_diff - value_diff.group.mean,
                m_market.preds = predict(m_market, newdata = event_data),
                m_fixed.preds = predict(m_fixed, newdata = event_data),
                m_mixed.preds = predict(m_mixed, newdata = event_data),
                m_hier.preds = predict(m_hier, newdata = event_data),
                m_market.AR = value_diff - m_market.preds,
                m_fixed.AR = value_diff - m_fixed.preds,
                m_mixed.AR = value_diff - m_mixed.preds,
                m_hier.AR = value_diff - m_hier.preds) |>
                add_row(estimation_data)


augmented_data |> 
    filter(!is.na(partner_name)) |> 
        select(Period,acquired,partner_name, partnership, BankName, value_diff,  m_market.preds,m_fixed.preds,m_hier.preds, m_mixed.preds,value_diff.est.mean) |>
            pivot_longer(cols = 6:last_col()) |>
                ggplot(aes(x = Period, y = value, colour = name)) +
                    geom_line() + 
                    geom_vline(xintercept = 0, linetype=4) +
                    facet_wrap(~partner_name+partnership+BankName, ncol=2) + scale_x_continuous(breaks = -10:3) +scale_colour_colorblind7() 
                    

augmented_data |> filter(!is.na(partner_name), Period >=0) |> 
select(Period,partner_name, partnership, BankName, AR_mean, AR_group,m_hier.AR,m_fixed.AR, m_mixed.AR, m_market.AR) |>
pivot_longer(cols = contains("AR", ignore.case=FALSE)) |>
ggplot(aes(x = Period, y = value, colour = name)) +
    geom_line() + geom_vline(xintercept = 0, linetype=4) +
                    facet_wrap(~partner_name+partnership+BankName, ncol=2) +
                    scale_colour_colorblind7() + scale_x_continuous(breaks = 0:3)

results |> 
    add_row(model="Market", rsme = run_kfold_validation(estimation_data, market_formula)) |>
    add_row(model="Fixed", rsme = run_kfold_validation(estimation_data, fixed_formula)) |>
    add_row(model="Mixed", rsme = run_kfold_validation(estimation_data, mixed_formula)) |>
    add_row(model="Hierarchy", rsme = run_kfold_validation(estimation_data, hier_formula, lmer)) 

estimation_data |> View()

results |> 
    add_row(model="Market", rsme = run_kfold_validation(estimation_data, market_formula)) |>
    add_row(model = "Market_TS", rsme = run_timeseries_cv(estimation_data, market_formula, initial_window = 20))


```

```{r}
lmer1_formula <- "value_diff  ~ (1 | IDRSSD) + value_diff.group.mean"
result <- run_timeseries_cv(estimation_data, lmer1_formula, model_func = lmer)
result_fixed <- run_timeseries_cv(estimation_data, lmer1_formula, model_func = lmer)


results |> 
    add_row(model="IMER", rsme = run_kfold_validation(estimation_data, lmer1_formula)) |>
    add_row(model = "IMER_TS", rsme = run_timeseries_cv(estimation_data, lmer1_formula, model_func = lmer)$OverallMeanRMSE)

data =estimation_data
formula_string = lmer1_formula
model_func = lmer -->

# non_partership_banks <- bank_data |> filter(is.na(name))
# partership_banks <- bank_data |> filter(!is.na(name))

# results <- tibble(model = character(),
#                     rsme = numeric())

# lmer1_formula <- "value_diff  ~ Qtr + RRSFS.Pop + RRSFS.Pop.lag1 + (1 | IDRSSD)"
# lmer2_formula <- "value_diff  ~ Qtr + RRSFS.Pop + RRSFS.Pop.lag1 + UNRATE + UNRATE.lag1 + (1 | IDRSSD)"
# lmer3_formula <- "value_diff  ~ Qtr + RRSFS.Pop + RRSFS.Pop.lag1 + UNRATE + UNRATE.lag1 + (1 | BankType/IDRSSD)"
# lmer4_formula <- "value_diff  ~ Qtr + (1 | BankType/IDRSSD) + BankType"
# lmer5_formula <- "value_diff  ~ Qtr + value_diff.group.mean + (1 | IDRSSD)"
# lmer6_formula <- "value_diff  ~ Qtr + value_diff.group.mean + (1 | BankType)"
# lmer7_formula <- "value_diff  ~ Qtr + value_diff.median + (1 | BankType)"
# lmer8_formula <- "value_diff  ~ Qtr + value_diff.group.mean + (1 | IDRSSD) + RRSFS.Pop + RRSFS.Pop.lag1"
# lmer9_formula <- "value_diff.detrend  ~ RRSFS.Pop + RRSFS.Pop.lag1 + UNRATE + UNRATE.lag1 + (1 | IDRSSD)"

# arima1_formula <- "value_diff ~ 1 + RRSFS.Pop.mean + RRSFS.Pop.lag1.mean + UNRATE.mean + UNRATE.lag1.mean"

# results |>
# add_row(model="LMER1", rsme =run_kfold_validation(non_partership_banks, lmer1_formula)) |>
# add_row(model="LMER2", rsme =run_kfold_validation(non_partership_banks, lmer2_formula)) |> 
# add_row(model="LMER3", rsme =run_kfold_validation(non_partership_banks, lmer3_formula)) |>
# add_row(model="LMER4", rsme =run_kfold_validation(non_partership_banks, lmer4_formula)) |>
# add_row(model="LMER5", rsme =run_kfold_validation(non_partership_banks, lmer5_formula)) |>
# add_row(model="LMER6", rsme =run_kfold_validation(non_partership_banks, lmer6_formula)) |>
# add_row(model="LMER7", rsme =run_kfold_validation(non_partership_banks, lmer7_formula)) |>
# add_row(model="LMER7", rsme =run_kfold_validation(non_partership_banks, lmer8_formula))|>
# add_row(model="LMER7", rsme =run_kfold_validation(non_partership_banks, lmer9_formula))
# add_row(model="ARIMA7", rsme =run_kfold_validation_arima(non_partership_banks, arima1_formula))


# best_model <- lmer(as.formula(lmer6_formula), data = non_partership_banks)
# partership_banks$preds <- predict(best_model, newdata = partership_banks)
# partership_banks$residuals <- partership_banks$value_diff - partership_banks$preds
# # If you know the actual outcomes for the test data
# test_rmse <- Metrics::rmse(partership_banks$value_diff, partership_banks$preds)

# partership_banks |> 
#     ggplot(aes(x = Quarter, y = value_diff, colour = EventPeriod)) +
#     geom_line(aes(y = preds))+ #, color = "blue") +  # Predicted fit
#     geom_point(aes(y = value_diff), color = "red", alpha = 0.5) +  # Observed data
#     facet_wrap(~ partnership+name+BankName, scales = "free_x") +  # Separate plot for each firm
#     labs(title = "Fitted Model for Each Firm", 
#         x = "Date", 
#         y = "value_diff")

# ggplot(acs(x))

# plot(test_preds, residuals, main="Residuals vs Predicted", xlab="Predicted Values", ylab="Residuals")
# abline(h=0, col="red")

# #create Q-Q plot for residuals
# qqnorm(residuals)
# #add a straight diagonal line to the plot
# qqline(residuals) 
# plot(density(partership_banks$residuals))
# plot(density(partership_banks |> filter(EventPeriod == FALSE) |> pull(residuals)))
# plot(density(partership_banks |> filter(EventPeriod == TRUE) |> pull(residuals)))




# bank_data |> View() 
# library(lme4)
# library(splines)

# quarter(yearquarter("2010 Q2"))

# m <- lmer(value_diff.detrend  ~ Qtr + (1 | BankType/IDRSSD) + BankType+ EventPeriod + (EventPeriod | IDRSSD), data = bank_data)

# m <- lmer(value_diff  ~ Qtr + value_diff.group.mean +  (EventPeriod | IDRSSD), data = bank_data)

# m <- lmer(value_diff  ~ Qtr + RRSFS.Pop+RRSFS.Pop.lag1 + UNRATE + UNRATE.lag1 + (EventPeriod | IDRSSD), data = bank_data)

# fit_consMR <- bank_data |> as_tsibble(key=c(BankName,name, partnership), index=Quarter) |>
#                 fabletools::model(tslm = TSLM(value_diff  ~ Qtr + (1 | IDRSSD) + value_diff.group.mean+ RRSFS.Pop+RRSFS.Pop.lag1 + UNRATE + UNRATE.lag1 + (EventPeriod | IDRSSD)))


# augmented_data <- fit_consMR |>filter(!is.na(name)) |>
#                      augment()

# augmented_data |>
#   ggplot(aes(x = Quarter)) +
#   geom_line(aes(y = value_diff, colour = "Data")) +
#   geom_line(aes(y = .fitted, colour = "Fitted")) +
#   facet_wrap(~ partnership+name+BankName, scales = "free_x") +
#   labs(y = NULL,
#     title = "Percent change in US consumption expenditure"
#   ) +
#   scale_colour_manual(values=c(Data="black",Fitted="#D55E00")) +
#   guides(colour = guide_legend(title = NULL)) 

# summary(m)
# bank_data$yhat <- predict(m, re.form = NULL)  # re.form = NULL to include random effects

# subset(bank_data, partner_event == 1) |>
#     ggplot(aes(x = Quarter, y = value_diff, colour = EventPeriod)) +
#     geom_line(aes(y = yhat))+ #, color = "blue") +  # Predicted fit
#     geom_point(aes(y = value_diff), color = "red", alpha = 0.5) +  # Observed data
#     facet_wrap(~ partnership+name+BankName, scales = "free_x") +  # Separate plot for each firm
#     labs(title = "Fitted Model for Each Firm", 
#         x = "Date", 
#         y = "Return")


    
        


# # Estimate And observation data
# est_data <- bank_data |> filter(between(Period, -6, -1))
# obs_data <- bank_data |> filter(between(Period, 0, 5)) 

# m_recipe <- recipe(bank_data) |>
#   update_role(everything(), new_role = "support") |> 
#   update_role(value_diff.Bank, new_role = "outcome") |>
#   update_role(value_diff.Agg, partnership, new_role = "predictor") |>
#   step_dummy(partnership, one_hot=T)

# # obs_data <- m_recipe |>
# #             prep(obs_data) |>
# #             bake(obs_data)

# m_model <- linear_reg() |> set_engine("lm")

# m_workflow <- workflow() |>
#                 add_recipe(m_recipe) |>
#                 add_model(m_model)

# m_fitted <- m_workflow |> fit(est_data)

# y_hat <- m_fitted |> predict(obs_data)

#   #metric_set(rmse, mae, rsq)(obs_data$value_diff.Bank, .pred)


# #https://mdneuzerling.com/post/machine-learning-pipelines-with-tidymodels-and-targets/
# #In the observation period, subtract the prediction from the actual return to get the “abnormal return.” 
# obs_data_ar <- bind_cols(obs_data, y_hat) |>
#     # Using mean of estimation return
#     mutate(
#         #mean = value_diff.Bank - mean(est_data$value_diff.Bank),
#         # Then comparing to peers
#         #peers = value_diff.Bank - value_diff.Agg,
#         # Then using model fit with estimation data
#         Predicted = .pred,
#         "Actual-Predicted" = value_diff.Bank - .pred)

# #put predictions and predictions together for visualisation
# actual <- bank_data |> 
#     filter(between(Period, -6, 5)) |> 
#     select(Period, partner_event = name, BankName, partnership, Actual=value_diff.Bank) 
   
# predict <- obs_data_ar |> 
#     select(Period, partner_event = name, BankName, partnership, Predicted) 
    
# actual |> left_join(predict) |>
# as_tsibble(index=Period, key=c(partner_event, BankName)) |>
# pivot_longer(cols=c(Actual,Predicted), names_to = "Values") |> 
#     autoplot(value,aes(color = Values)) + facet_grid(partnership ~ partner_event) +
#     theme(legend.position = "top")

# ```

# ##Evaluating the model
   
# The idea is this: when there’s supposed to be an effect, and we test for an effect, we can’t tease apart what part of our findings is the effect, and what part is the counterfactual model being wrong. But what if we knew there were no effect? Then, anything we estimated could only be the counterfactual model being wrong. So if we got an effect under those conditions, we’d know our model was fishy and would have to try something else.

# So, get a bunch of different time series to test, especially those unaffected by the event. In the context of stock returns, for example, don’t just include the firm with the great announcement on a certain day, also include stocks for a bunch of other firms that had no announcement.

# Then, start doing your event study over and over again. Except each time you do it, pick a random time series to do it on, and pick a random day when the “event” is supposed to have happened.21
# ```{r}
# selected_measure |>
#     as_tibble() |>
#     filter(LargeBank==1|LargeCreditCardBank==1) |>
#     left_join(partners, relationship = "many-to-many") |>
#     rename(value_diff.Bank = value_diff) |>
#     mutate(Period = Quarter - yearquarter(acquired)) 

# ```